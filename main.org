#+TITLE: Main file
#+AUTHOR: Hugo Ávila (@bioinformagica)
#+LANGUAGE: en-us
#+STARTUP: overview
#+PROPERTY: header-args :dir ~/projects/salmonella-bacterial-immunity :mkdirp yes :exports none :eval never-export

* ENV setup
** Snakemake
#+BEGIN_SRC shell
# get conda installer
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# Run installer and interactively accept and init the conda executable
# Atention !!!: this will change your current shell .rc (.zshrc, .bashrc ...)
bash Miniconda3-latest-Linux-x86_64.sh

# Source the conda changes
source ~/.bashrc

# Set auto activation of conda base environment to false
conda config --set auto_activate_base false

# Add channels
conda config --add channels conda-forge
conda config --add channels bioconda

# Install mamba
conda install -n base -c conda-forge mamba -y

# Install Snakemake
mamba create -c conda-forge -c bioconda -n snakemake snakemake -y

#+END_SRC

#+RESULTS:

* README.md
#+NAME: cb:README.md
#+CAPTION: README.md
#+BEGIN_SRC markdown :tangle README.md
# Snakemake workflow: `salmonella-bacterial-immunity`

[![Snakemake](https://img.shields.io/badge/snakemake-≥6.3.0-brightgreen.svg)](https://snakemake.github.io)

A Snakemake workflow for `Find new defense systems on Salmonella`.
#+END_SRC
** DONE Create README.md
** TODO Create linter action
* Snakefile
:PROPERTIES:
:COOKIE_DATA: todo recursive
:header-args: :tangle workflow/Snakefile :mkdirp yes :exports none :eval never-export :comments link
:END:
** IMPORTS
#+BEGIN_SRC snakemake
import os
import sys
import random
random.seed(42)
#+END_SRC

** FILE CONFIGS
#+BEGIN_SRC snakemake
configfile: 'config/config.yaml'
#+END_SRC

** FUNCTIONS
#+BEGIN_SRC snakemake
get_cores_perc = lambda perc: max(1, workflow.cores * perc)
join_path = lambda *args: os.path.join(*args)
#+END_SRC

** GLOBAL VARIABLES
#+BEGIN_SRC snakemake
snakefile_path = os.path.dirname(workflow.snakefile)
results_dir = join_path('results')
scripts_dir = join_path(snakefile_path, 'scripts')

# Globs
GENOME_IDS = list(map(lambda x: x.name.replace('_out', ''), filter(lambda x: x.is_dir(), Path(config['prokka_dir']).iterdir())))

# Run only for a sub sample of the input,
# config['sample_input'] must be a interger value >= 1.
if isinstance(config['sample_input'], int) and config['sample_input'] >= 1:
    GENOME_IDS = random.sample(GENOME_IDS, config['sample_input'])
#+END_SRC
** MAIN RULE ALL
#+BEGIN_SRC snakemake
rule all:
    input:
        mmseqs2_tsv = join_path(results_dir, 'cassettes', 'clusters', 'mmseqs2_cluster.tsv'),
#+END_SRC

** Include
#+BEGIN_SRC snakemake
include:
    'rules/get_gene_neighborhood.smk'
#+END_SRC

* Rules
** Get Gene Neighborhood
:PROPERTIES:
:COOKIE_DATA: todo recursive
:header-args: :tangle workflow/rules/get_gene_neighborhood.smk :mkdirp yes :exports none :eval never-export :comments link
:END:
*** Find defense genes with padloc
#+BEGIN_SRC snakemake
rule padloc_search_defense_genes    :
    input:
        gff_file = join_path(config['prokka_dir'], '{genome_id}_out', '{genome_id}_out.gff'),
        faa_file = join_path(config['prokka_dir'], '{genome_id}_out', '{genome_id}_out.faa')
    output:
        padloc_out_dir = directory(join_path(results_dir, 'padloc', '{genome_id}')),
        padloc_csv = join_path(results_dir, 'padloc', '{genome_id}', '{genome_id}_out_padloc.csv'),
    params:
        gff_nofasta_file = join_path(config['prokka_dir'], '{genome_id}_out', '{genome_id}_out_nofasta.gff'),
    threads:
        get_cores_perc(0.1)
    conda:
        '../envs/padloc_env.yaml'
    shell:
        "sed '/^##FASTA/Q' {input.gff_file} > {params.gff_nofasta_file} && "
        'mkdir -p {output.padloc_out_dir} && '
        'padloc --faa {input.faa_file} --gff {params.gff_nofasta_file} --outdir {output.padloc_out_dir} && '
        'rm -v {params.gff_nofasta_file}'
#+END_SRC
*** Find defense genes with defense finder
#+BEGIN_SRC snakemake
rule defensefinder_search_defense_genes:
    input:
        faa_file = join_path(config['prokka_dir'], '{genome_id}_out', '{genome_id}_out.faa'),
    output:
        defensefinder_out_dir = directory(join_path(results_dir, 'defensefinder', '{genome_id}')),
        defensefinder_tsv = join_path(results_dir, 'defensefinder', '{genome_id}', 'defense_finder_systems.tsv'),
    params:
        ,**config['params']['defensefinder'],
    threads:
        get_cores_perc(0.1)
    conda:
        '../envs/defensefinder_env.yaml'
    shell:
        'defense-finder run '
        '--db-type {params.db_type} '
        '--out-dir {output.defensefinder_out_dir} '
        '--workers {threads} '
        '{input.faa_file} '
#+END_SRC
*** Get gene cassettes
#+BEGIN_SRC snakemake
rule get_gene_cassettes:
    input:
        gbk_file = join_path(config['prokka_dir'], '{genome_id}_out', '{genome_id}_out.gbk'),
        defensefinder_tsv = join_path(results_dir, 'defensefinder', '{genome_id}', 'defense_finder_systems.tsv'),
        padloc_csv = join_path(results_dir, 'padloc', '{genome_id}', '{genome_id}_out_padloc.csv'),
        script = join_path(scripts_dir, 'extract_cassettes.py'),
    output:
        gene_cassettes_dir = directory(join_path(results_dir, 'cassettes', 'extracted', '{genome_id}')),
        cassettes_faa = join_path(results_dir, 'cassettes', 'extracted', '{genome_id}', 'Cassettes.faa'),
        merged_padloc_deffind_csv = join_path(results_dir, 'cassettes', 'extracted', '{genome_id}', 'merged_defense_systems_prediction.csv'),
    params:
        ,**config['params']['get_gene_cassettes'],
        log_dir = join_path(snakefile_path, '..', 'logs'),
    conda:
        '../envs/misc_env.yaml'
    threads:
        1
    shell:
       'exec &> >( tee {params.log_dir}/{rule}_{wildcards.genome_id}_$(date +%Y_%m_%d_-_%H_%M_%S).log ) && '
       'python3 {input.script} '
       '--gbk_file {input.gbk_file} '
       '--padloc_table {input.padloc_csv} '
       '--defensefinder_table {input.defensefinder_tsv} '
       '--output_path {output.gene_cassettes_dir} '
       '--n_genes {params.n_genes}'
#+END_SRC
*** Combine faa files
#+BEGIN_SRC snakemake
rule merge_cassette_proteins:
    input:
        cassettes_faa = expand(join_path(results_dir, 'cassettes', 'extracted', '{genome_id}', 'Cassettes.faa'), genome_id=GENOME_IDS),
    output:
        concatenated_faa_file = join_path(results_dir, 'cassettes', 'clusters', 'merged_cassette_proteins.faa.gz')
    threads:
        1
    shell:
        'cat {input.cassettes_faa} | gzip > {output.concatenated_faa_file}'
#+END_SRC
*** Cluster cassette genes
#+BEGIN_SRC snakemake
rule mmseqs2_cluster_proteins:
    input:
        concatenated_faa_file = join_path(results_dir, 'cassettes', 'clusters', 'merged_cassette_proteins.faa.gz')
    output:
        mmseqs2_rep = join_path(results_dir, 'cassettes', 'clusters', 'mmseqs2_rep_seq.fasta'),
        mmseqs2_tsv = join_path(results_dir, 'cassettes', 'clusters', 'mmseqs2_cluster.tsv'),
    params:
        ,**config['params']['mmseqs2'],
        mmseqs2_prefix = join_path(results_dir, 'cassettes', 'clusters', 'mmseqs2'),
        mmseqs2_fasta = join_path(results_dir, 'cassettes', 'clusters', 'mmseqs2_all_seqs.fasta'),
        mmseqs2_tmp = join_path(results_dir, 'cassettes', 'clusters', 'tmp'),
    conda:
        '../envs/mmseqs2_env.yaml'
    threads:
        get_cores_perc(1)
    shell:
        'mmseqs easy-cluster {input.concatenated_faa_file} {params.mmseqs2_prefix} '
        '{params.mmseqs2_tmp} --threads {threads} '
        '-c {params.min_cov} --min-seq-id {params.min_ide} && rm -v {params.fasta}'

#+END_SRC


* CONFIGS
:PROPERTIES:
:COOKIE_DATA: todo recursive
:header-args: :tangle config/config.yaml :mkdirp yes :exports none :eval never-export :comments link
:END:
#+BEGIN_SRC yaml
prokka_dir: 'results/Prokka'
sample_input: 'no' # interger (sample_input 1 for testing) or 'no' for all

params:
  defensefinder:
    db_type: 'ordered_replicon'
  get_gene_cassettes:
    n_genes: 10 # number of genes to get up and down stream from the interest genes
  mmseqs2:
    min_cov: 0.8
    min_ide: 0.5

#+END_SRC
* Notes
